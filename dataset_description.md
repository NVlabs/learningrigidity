# About the Generated Refresh Dataset

The data is generated using the [RefRESH Toolkit][1]. If you want to generate your own data for training, please check the RefRESH repository.

If you want to download the pre-generated data used in the paper at: 
[RefRESH data using BundleFusion][2]. 

The calibration and camera pose ground truth are in the info.pkl for each trajectory: e.g. ‘office3/keyframe_1/0000_0100’. The .pkl file was generated by python 2 pickle module. If you load it using python3 please be aware of using python2 pickle module to read :

``` python
with open('info.pkl', 'rb') as p:
    # the original pickle is in python2
    files = pickle.load(p, encoding='latin1')
```

To read the calibration file from the pickle: 
``` python
calib = files['calib']
# note that the color and depth calibration has very small shift
# (< 0.2 (582.vs 583)). We will only use depth intrinsic since
# it gives very good approximation
Ks = calib['depth_intrinsic']
```

To read the camera pose from the pickle:
``` python
poses = files['pose']
```

## Several Notes: 
* The keyframe indicates the number of frame intervals we used at rendering. In each keyframe sequence, the length of the sequence are 100 at most.

* The provided optical flow model is **backward optical flow**, Please be aware of it if you use it to train your dataset. The current toolkit in [RefRESH][1] has been updated to support rendering bidirection optical flow. If you need this feature, you can render the data using that tool.

[1]: https://github.com/lvzhaoyang/RefRESH
[2]: https://drive.google.com/drive/folders/1DMb3qpoYoowa00EfzGzTKySbT_WIbhD7?usp=sharing

